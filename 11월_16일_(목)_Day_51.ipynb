{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0NuOkxr+TtXcorsf+LfIn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cowsilver57/sessac_test/blob/main/11%EC%9B%94_16%EC%9D%BC_(%EB%AA%A9)_Day_51.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Single Layer Backpropagation"
      ],
      "metadata": {
        "id": "8giAJlCmIMvQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "U5JzKJf6CusY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class AffineFunction:\n",
        "    def __init__(self):\n",
        "        np.random.seed(0)\n",
        "        w = np.random.randn(2)\n",
        "        b = np.random.randn()\n",
        "    def forward(self,x):\n",
        "        self.x = x\n",
        "        z = np.dot(self.w, x) + self.b\n",
        "        return z\n",
        "    def backward(self, dJ_dz, lr):\n",
        "        #자기자신 미분 값\n",
        "        dz_dw = self.x\n",
        "        dz_db = 1\n",
        "        #도출 값 = 자기자신 미분 값 * 뒤에서 넘어온 미분 값\n",
        "        dJ_dw = dz_dw * dJ_dz\n",
        "        dJ_db = dz_db * dJ_dz\n",
        "        #최종 값 구하기\n",
        "        self.w = self.w - lr*dJ_dw\n",
        "        self.b = self.b - lr*dJ_db\n",
        "\n",
        "class SigmoidFunction:\n",
        "    def forward(self, z):\n",
        "        self.a = 1/(1+np.exp(-z))\n",
        "        return self.a\n",
        "    def backward(self, dJ_dpred):\n",
        "        #자기자신 미분 값\n",
        "        dpred_dz = self.a*(1-self.a)\n",
        "        #도출 값 = 자기자신 값 * 뒤에서 넘어온 미분 값\n",
        "        dJ_dz = dpred_dz * dJ_dpred\n",
        "        return dJ_dz\n",
        "\n",
        "class Model:\n",
        "    def __init__(self):\n",
        "        self.affine = AffineFunction()\n",
        "        self.activation = SigmoidFunction()\n",
        "    def forward(self, x):\n",
        "        z = self.affine.forward(x)\n",
        "        pred = self.activation.forward(z)\n",
        "        return pred\n",
        "    def backward(self, dJ_dpred, lr):\n",
        "        dJ_dz = self.activation.backward(dJ_dpred)\n",
        "        self.affine.backward(dJ_dz, lr)\n",
        "\n",
        "class BCELoss:\n",
        "    def forward(self, pred, y):\n",
        "        self.pred = pred\n",
        "        self.y = y\n",
        "        J = -(y*np.log(pred)+(1-y)*np.log(1-pred))\n",
        "        return J\n",
        "    def backward(self):\n",
        "        dJ_dpred = (self.pred-self.y)/(self.pred*(1-self.pred))\n",
        "        return dJ_dpred"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Multi Layer Backpropagation"
      ],
      "metadata": {
        "id": "rb3sBh3wISYw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2-1. affine + sigmoid 로  Neuron class 만들기"
      ],
      "metadata": {
        "id": "Ukva58v3KsXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class AffineFunction:\n",
        "    def __init__(self):\n",
        "        np.random.seed(0)\n",
        "        self.w = np.random.randn(2)\n",
        "        self.b = np.random.randn()\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        z = np.dot(self.w, x) + self.b\n",
        "        return z\n",
        "    def backward(self, dJ_dz1, dJ_dz2, lr):\n",
        "        dz_dw11, dz_dw12 = self.x, self.x\n",
        "        dz_dw21, dz_dw22 = self.x, self.x\n",
        "        dz_db1, dz_db2 = 1, 1\n",
        "\n",
        "        #Layer 1\n",
        "        dJ_dw11 = dz_dw11 * dJ_dz1\n",
        "        dJ_dw12 = dz_dw12 * dJ_dz1\n",
        "        dJ_db1 = dz_db1 * dJ_dz1\n",
        "        #Layer 2\n",
        "        dJ_dw21 = dz_dw21 * dJ_dz2\n",
        "        dJ_dw22 = dz_dw22 * dJ_dz2\n",
        "        dJ_db2 = dz_db2 * dJ_dz2\n",
        "\n",
        "        self.w11 = self.w11 - lr * dJ_dw11\n",
        "        self.w12 = self.w12 - lr * dJ_dw12\n",
        "        self.b = self.b1 - lr * dJ_db1\n",
        "        self.w21 = self.w21 - lr * dJ_dw21\n",
        "        self.w22 = self.w22 - lr * dJ_dw22\n",
        "        self.b2 = self.b2 - lr * dJ_db2\n",
        "\n",
        "class SigmoidFunction:\n",
        "    def forward(self, z):\n",
        "        self.a = 1 / (1 + np.exp(-z))\n",
        "        return self.a\n",
        "    def backward(self, dJ_dpred):\n",
        "        dpred_dz = self.a * (1 - self.a)\n",
        "        dJ_dz = dpred_dz * dJ_dpred\n",
        "        return dJ_dz\n",
        "\n",
        "class Neuron:\n",
        "    def __init__(self):\n",
        "        self.affine = AffineFunction()\n",
        "        self.sigmoid = SigmoidFunction()\n",
        "    def forward(self, x):\n",
        "        z = self.affine.forward(x)\n",
        "        pred = self.sigmoid.forward(z)\n",
        "        return pred\n",
        "    def backward(self, dJ_dpred, lr):\n",
        "        dJ_dz = self.sigmoid.backward(dJ_dpred)\n",
        "        dJ_dx = self.affine.backward(dJ_dz, lr)\n",
        "        return dJ_dx"
      ],
      "metadata": {
        "id": "Z2FkzAVELWdN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2-2. neuron 3개로 model class 만들기"
      ],
      "metadata": {
        "id": "pjBjzGtuKzoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model:\n",
        "    def __init__(self):\n",
        "        self.neuron1 = Neuron()\n",
        "        self.neuron2 = Neuron()\n",
        "        self.neuron3 = Neuron()\n",
        "    #Layer1\n",
        "    def forward(self, x):\n",
        "        Layer1_pred1 = self.neuron1.forward(x)\n",
        "        Layer1_pred2 = self.neuron2.forward(x)\n",
        "    #Layer2\n",
        "    def forward(self, Layer1_pred1, Layer1_pred2):\n",
        "        Layer2_pred = self.neuron3.forward(np.array([Layer1_pred1, Layer1_pred2]))\n",
        "        return Layer2_pred\n",
        "\n",
        "    def backward(self, dJ_dpred, lr):\n",
        "        dJ_dz3 = self.neuron3.backward(dJ_dpred)\n",
        "        dJ_dz1 = self.neuron2.backward(dJ_dz3, lr)\n",
        "        dJ_dz2 = self.neuron1.backward(dJ_dz3, lr)\n",
        "        return dJ_dz1, dJ_dz2\n",
        "\n",
        "class BCELoss:\n",
        "    def forward(self, Layer2_pred, y):\n",
        "        self.Layer2_pred = Layer2_pred\n",
        "        self.y = y\n",
        "        J = -(y*np.log(Layer2_pred)+(1-y)*np.log(1-Layer2_pred))\n",
        "        return J\n",
        "    def backward(self):\n",
        "        dJ_dpred = (self.pred-self.y)/(self.pred*(1-self.pred))\n",
        "        return dJ_dpred"
      ],
      "metadata": {
        "id": "Z478TIDtJm1x"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##전체 모델 코드"
      ],
      "metadata": {
        "id": "RbU896om0stA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class AffineFunction:\n",
        "    def __init__(self, n_x):\n",
        "        np.random.seed(0)\n",
        "        self.w = np.random.randn(n_x)\n",
        "        self.b = np.random.randn()\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        z = np.dot(self.w, x) + self.b\n",
        "        return z\n",
        "    def backward(self, dJ_dz, lr):\n",
        "        dz_dw = self.x\n",
        "        dz_db = 1\n",
        "\n",
        "        dJ_dw = np.outer(dz_dw, dJ_dz)\n",
        "        dJ_db = dz_db * dJ_dz\n",
        "\n",
        "        self.w = self.w - lr * dJ_dw\n",
        "        self.b = self.b - lr * dJ_db\n",
        "\n",
        "        dJ_dx = np.dot(self.w, dJ_dz)\n",
        "        return dJ_dx\n",
        "\n",
        "class SigmoidFunction:\n",
        "    def forward(self, z):\n",
        "        self.a = 1 / (1 + np.exp(-z))\n",
        "        return self.a\n",
        "    def backward(self, dJ_dpred):\n",
        "        dpred_dz = self.a * (1 - self.a)\n",
        "        dJ_dz = dpred_dz * dJ_dpred\n",
        "        return dJ_dz\n",
        "\n",
        "class Neuron:\n",
        "    def __init__(self, n_x):\n",
        "        self.affine = AffineFunction()\n",
        "        self.sigmoid = SigmoidFunction()\n",
        "    def forward(self, x):\n",
        "        z = self.affine.forward(x)\n",
        "        pred = self.sigmoid.forward(z)\n",
        "        return pred\n",
        "    def backward(self, dJ_dpred, lr):\n",
        "        dJ_dz = self.sigmoid.backward(dJ_dpred)\n",
        "        dJ_dx = self.affine.backward(dJ_dz, lr)\n",
        "        return dJ_dx\n",
        "\n",
        "class Model:\n",
        "    def __init__(self):\n",
        "        self.neuron1 = Neuron(n_x=2)\n",
        "        self.neuron2 = Neuron(n_x=2)\n",
        "        self.neuron3 = Neuron(n_x=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        Layer1_pred1 = self.neuron1.forward(x)\n",
        "        Layer1_pred2 = self.neuron2.forward(x)\n",
        "        Layer2_pred = self.neuron3.forward(np.array([Layer1_pred1, Layer1_pred2]))\n",
        "        return Layer2_pred\n",
        "\n",
        "    def backward(self, dJ_dpred, lr):\n",
        "        dJ_dz3 = self.neuron3.backward(dJ_dpred)\n",
        "        dJ_dz1 = self.neuron2.backward(dJ_dz3[0], lr)\n",
        "        dJ_dz2 = self.neuron1.backward(dJ_dz3[1], lr)\n",
        "        return dJ_dz1, dJ_dz2\n",
        "\n",
        "class BCELoss:\n",
        "    def forward(self, Layer2_pred, y):\n",
        "        self.Layer2_pred = Layer2_pred\n",
        "        self.y = y\n",
        "        J = -(y*np.log(Layer2_pred)+(1-y)*np.log(1-Layer2_pred))\n",
        "        return J\n",
        "    def backward(self):\n",
        "        dJ_dpred = (self.pred-self.y)/(self.pred*(1-self.pred))\n",
        "        return dJ_dpred"
      ],
      "metadata": {
        "id": "InOkn_JC0t3u"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 학습시키기"
      ],
      "metadata": {
        "id": "-HCReZVL7M5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "EPOCHS = 10000\n",
        "LR = 0.3\n",
        "\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([0, 1, 1, 0])\n",
        "\n",
        "class Model:\n",
        "    def __init__(self):\n",
        "        self.neuron1_1 = Neuron(n_x=2)\n",
        "        self.neuron1_2 = Neuron(n_x=2)\n",
        "        self.neuron2 = Neuron(n_x=2)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        a1_1 = self.neuron1_1(x)\n",
        "        a1_2 = self.neuron1_2(x)\n",
        "        a1 = np.array([a1_1, a1_2])\n",
        "\n",
        "        pred = self.neuron2(a1)\n",
        "        return pred\n",
        "\n",
        "    def backward(self, dJ_dpred, lr):\n",
        "        dJ_da1 = self.neuron2.backward(dJ_dpred, lr)\n",
        "\n",
        "        self.neuron1_1.backward(dJ_da1[0], lr)\n",
        "        self.neuron1_2.backward(dJ_da1[1], lr)\n",
        "\n",
        "\n",
        "model = Model()\n",
        "loss_function = BCELoss()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    for x_, y_ in zip(X, y):\n",
        "        pred = model(x_)\n",
        "        J = loss_function(pred, y_)\n",
        "\n",
        "        dJ_dpred = loss_function.backward()\n",
        "        model.backward(dJ_dpred, LR)\n",
        "\n",
        "x1 = np.linspace(-0.5, 1.5, 100)\n",
        "x2 = np.linspace(-0.5, 1.5, 100)\n",
        "X1, X2 = np.meshgrid(x1, x2)\n",
        "X = np.hstack([X1.reshape(-1, 1), X2.reshape(-1, 1)])\n",
        "y = []\n",
        "for x in X: y.append(model(x))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "ax.scatter(X[:, 0], X[:, 1], c=y, cmap='bwr')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "SP49r-cy7Oaq",
        "outputId": "cfe5fdff-444a-4d3a-e94b-34e0d2374e4b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-414989dfd3cc>\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mloss_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-414989dfd3cc>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneuron1_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneuron1_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneuron2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-a9acc4356514>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, n_x)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mNeuron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maffine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAffineFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSigmoidFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: AffineFunction.__init__() missing 1 required positional argument: 'n_x'"
          ]
        }
      ]
    }
  ]
}