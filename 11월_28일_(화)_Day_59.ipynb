{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7uo0MCLn+so4LawRWRlOc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cowsilver57/sessac_test/blob/main/11%EC%9B%94_28%EC%9D%BC_(%ED%99%94)_Day_59.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#VGG 13 구현하기"
      ],
      "metadata": {
        "id": "5k6nkrERe5Tq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "class VGG13(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VGG13,self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=64,kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64,kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        self.Classifier = nn.Sequential(\n",
        "            nn.Linear(in_features=512*7*7, out_features=4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=4096, out_features=4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=4096, out_features=1000))\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "\n",
        "        x = x.view(x.shape[0],-1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "ua1pvTDQeHF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VGG 19 구현하기"
      ],
      "metadata": {
        "id": "JNQCcsgvjqTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "class VGG19(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VGG19,self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=64,kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64,kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        self.Classifier = nn.Sequential(\n",
        "            nn.Linear(in_features=512*7*7, out_features=4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=4096, out_features=4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=4096, out_features=1000))\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "\n",
        "        x = x.view(x.shape[0],-1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "qht1ORYHjrtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ConvBlock 만들기"
      ],
      "metadata": {
        "id": "p53Pfge5vfzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, n_layers):\n",
        "        super(ConvBlock, self).__init__()\n",
        "\n",
        "        #처음 conv layer는 in_channels를 사용\n",
        "        self.layers = [\n",
        "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                      kernel_size=3, padding=1),\n",
        "            nn.ReLU()\n",
        "        ]\n",
        "        #n_layer가 2 이상일 때 동작하는 코드\n",
        "        for _ in range(n_layers-1):\n",
        "            self.layers.append(nn.Conv2d(in_channels=out_channels, out_channels=out_channels,\n",
        "                                         kernel_size=3, padding=1))\n",
        "            self.layers.append(nn.ReLU())\n",
        "\n",
        "        #마지막에 max pooling 추가\n",
        "        self.layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        #list 안에 들어있는 layer를 풀어 nn.Sequential에 입력\n",
        "        self.layers = nn.Sequential(*self.layers)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.layers(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "x8XVVZ6kvxh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ConvBlock layer 구분 없이 만들기"
      ],
      "metadata": {
        "id": "0rPsxQPixHLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, n_layers):\n",
        "        super(ConvBlock, self).__init__()\n",
        "\n",
        "        self.layers = []\n",
        "        for _ in range(n_layers):\n",
        "            self.layers.append(nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                                         kernel_size=3, padding=1))\n",
        "            self.layers.append(nn.ReLU())\n",
        "            in_channels = out_channels\n",
        "\n",
        "        self.layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        self.layers = nn.Sequential(*self.layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layers(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "vwgQje0-xKHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "block = ConvBlock(in_channels=3, out_channels=64, n_layers=1)\n",
        "summary(block, input_size=(3,100,100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3CoXFNNVr8v",
        "outputId": "3b7bc665-a5d5-4b93-add8-ead8d704edbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 100, 100]           1,792\n",
            "              ReLU-2         [-1, 64, 100, 100]               0\n",
            "         MaxPool2d-3           [-1, 64, 50, 50]               0\n",
            "================================================================\n",
            "Total params: 1,792\n",
            "Trainable params: 1,792\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.11\n",
            "Forward/backward pass size (MB): 10.99\n",
            "Params size (MB): 0.01\n",
            "Estimated Total Size (MB): 11.11\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "block = ConvBlock(in_channels=3, out_channels=64, n_layers=2)\n",
        "summary(block, input_size=(3,100,100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdIOSx8AW0T9",
        "outputId": "78a88047-3589-46c5-b22c-fd5c0cb692a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 100, 100]           1,792\n",
            "              ReLU-2         [-1, 64, 100, 100]               0\n",
            "            Conv2d-3         [-1, 64, 100, 100]          36,928\n",
            "              ReLU-4         [-1, 64, 100, 100]               0\n",
            "         MaxPool2d-5           [-1, 64, 50, 50]               0\n",
            "================================================================\n",
            "Total params: 38,720\n",
            "Trainable params: 38,720\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.11\n",
            "Forward/backward pass size (MB): 20.75\n",
            "Params size (MB): 0.15\n",
            "Estimated Total Size (MB): 21.01\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "block = ConvBlock(in_channels=3, out_channels=64, n_layers=3)\n",
        "summary(block, input_size=(3,100,100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dI3cWYerkRG0",
        "outputId": "5f1c3b4d-b047-47af-edd9-a3f924f86f4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 100, 100]           1,792\n",
            "              ReLU-2         [-1, 64, 100, 100]               0\n",
            "            Conv2d-3         [-1, 64, 100, 100]          36,928\n",
            "              ReLU-4         [-1, 64, 100, 100]               0\n",
            "            Conv2d-5         [-1, 64, 100, 100]          36,928\n",
            "              ReLU-6         [-1, 64, 100, 100]               0\n",
            "         MaxPool2d-7           [-1, 64, 50, 50]               0\n",
            "================================================================\n",
            "Total params: 75,648\n",
            "Trainable params: 75,648\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.11\n",
            "Forward/backward pass size (MB): 30.52\n",
            "Params size (MB): 0.29\n",
            "Estimated Total Size (MB): 30.92\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conv Block을 이용해서 Model 구현하기"
      ],
      "metadata": {
        "id": "ZOT_orpj1wxp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conv Block을 이용해서 VGG 11 구현하기"
      ],
      "metadata": {
        "id": "EUsuLynamYtp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, n_layers):\n",
        "        super(ConvBlock, self).__init__()\n",
        "\n",
        "        layers = []\n",
        "        for _ in range(n_layers):\n",
        "            layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
        "            layers.append(nn.ReLU())\n",
        "            in_channels = out_channels\n",
        "\n",
        "        layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layers(x)\n",
        "        return x\n",
        "\n",
        "class VGG11_ConvBlock(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VGG11_ConvBlock, self).__init__()\n",
        "\n",
        "        self.conv1 = ConvBlock(in_channels=3, out_channels=64, n_layers=1)\n",
        "        self.conv2 = ConvBlock(in_channels=64, out_channels=128, n_layers=1)\n",
        "        self.conv3 = ConvBlock(in_channels=128, out_channels=256, n_layers=2)\n",
        "        self.conv4 = ConvBlock(in_channels=256, out_channels=512, n_layers=2)\n",
        "        self.conv5 = ConvBlock(in_channels=512, out_channels=512, n_layers=2)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(in_features=512*7*7, out_features=4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=4096, out_features=4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=4096, out_features=1000)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "eOHAX2J5mdvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conv Block을 이용해서 VGG 13 구현하기"
      ],
      "metadata": {
        "id": "GMY0ZAi_nS1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, n_layers):\n",
        "        super(ConvBlock, self).__init__()\n",
        "\n",
        "        layers = []\n",
        "        for _ in range(n_layers):\n",
        "            layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
        "            layers.append(nn.ReLU())\n",
        "            in_channels = out_channels\n",
        "\n",
        "        layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layers(x)\n",
        "        return x\n",
        "\n",
        "class VGG13_ConvBlock(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VGG13_ConvBlock, self).__init__()\n",
        "\n",
        "        self.conv1 = ConvBlock(in_channels=3, out_channels=64, n_layers=2)\n",
        "        self.conv2 = ConvBlock(in_channels=64, out_channels=128, n_layers=2)\n",
        "        self.conv3 = ConvBlock(in_channels=128, out_channels=256, n_layers=4)\n",
        "        self.conv4 = ConvBlock(in_channels=256, out_channels=512, n_layers=4)\n",
        "        self.conv5 = ConvBlock(in_channels=512, out_channels=512, n_layers=4)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(in_features=512 * 7 * 7, out_features=4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=4096, out_features=4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=4096, out_features=1000)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "ds4izTHenT7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conv Block을 이용해서 VGG 19 구현하기"
      ],
      "metadata": {
        "id": "_7AZJW4B1-cL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, n_layers):\n",
        "        super(ConvBlock, self).__init__()\n",
        "\n",
        "        layers = []\n",
        "        for _ in range(n_layers):\n",
        "            layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
        "            layers.append(nn.ReLU())\n",
        "            in_channels = out_channels\n",
        "\n",
        "        layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layers(x)\n",
        "        return x\n",
        "\n",
        "class VGG19_ConvBlock(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VGG19_ConvBlock, self).__init__()\n",
        "\n",
        "        self.conv1 = ConvBlock(in_channels=3, out_channels=64, n_layers=2)\n",
        "        self.conv2 = ConvBlock(in_channels=64, out_channels=128, n_layers=2)\n",
        "        self.conv3 = ConvBlock(in_channels=128, out_channels=256, n_layers=4)\n",
        "        self.conv4 = ConvBlock(in_channels=256, out_channels=512, n_layers=4)\n",
        "        self.conv5 = ConvBlock(in_channels=512, out_channels=512, n_layers=4)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(in_features=512 * 7 * 7, out_features=4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=4096, out_features=4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=4096, out_features=1000)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Jbk1OjHe2Cb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CIFAR 10 Dataset 적용하기"
      ],
      "metadata": {
        "id": "q7hOCpcU2Vid"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1oCFlTbA2ZTD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}